{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pylint: disable=no-member, missing-function-docstring\n",
    "\"\"\"Classification Algorithm that classify retinal image to three classes: \n",
    "Normal, Drusen, and Exudate retinal fundus images.\n",
    "Platform: Python 3.10.7 64-bit\n",
    "Evaluation Criteria: \n",
    "    - Sensitivity, specificity, accuracy, F-score, AUC, and confusion matrix\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, classification_report\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### preprocess the images ###########################\n",
    "def preprocess_image(image_path, target_size):\n",
    "    # Load and preprocess a single image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB format\n",
    "    # Resize the image using bilinear interpolation\n",
    "    image = cv2.resize(image, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "    # Normalize the image pixel values to 0-1 scale\n",
    "    image = image.astype('float32')/255.0\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### Load the images ###############################\n",
    "def load_images_from_directory(directory, target_size):\n",
    "    image_list = []\n",
    "    label_list = []\n",
    "\n",
    "    # Specify the class labels\n",
    "    class_labels = [\"normal\", \"exudates\", \"drusen\"]\n",
    "\n",
    "    # Iterate over the subdirectories (classes) in the directory\n",
    "    for class_name in class_labels:\n",
    "        class_dir = os.path.join(directory, class_name)\n",
    "        if os.path.isdir(class_dir):\n",
    "            # Iterate over the images in the class directory\n",
    "            for filename in os.listdir(class_dir):\n",
    "                # Adjust the file extensions as needed\n",
    "                if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                    image_path = os.path.join(class_dir, filename)\n",
    "                    image = preprocess_image(image_path, target_size)\n",
    "                    image_list.append(image)\n",
    "                    label_list.append(class_name)\n",
    "\n",
    "    # Convert the image list and label list to NumPy arrays\n",
    "    image_array = np.array(image_list)\n",
    "    label_array = np.array(label_list)\n",
    "\n",
    "    return image_array, label_array, class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# Training the CNN model #################################\n",
    "def cnn_model(y_train, y_test, X_train, X_test, label_encoder, target_size):\n",
    "\n",
    "    # Convert the string labels to numeric format\n",
    "    y_train = label_encoder.fit_transform(y_train)\n",
    "    y_test = label_encoder.transform(y_test)\n",
    "\n",
    "    # Define the CNN model architecture\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu',\n",
    "              input_shape=(target_size[0], target_size[1], 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=32,\n",
    "              validation_data=(X_test, y_test))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### Evaluate the model on the test data ###############################\n",
    "def evaluate_model(model, y_test, X_test, class_labels, label_encoder):\n",
    "    # Make predictions on the test set\n",
    "    probabilities = model.predict(X_test)\n",
    "    # Convert probabilities to class labels\n",
    "    y_pred = probabilities.argmax(axis=1)\n",
    "    y_pred = label_encoder.transform(y_pred)\n",
    "\n",
    "    # Calculate AUC\n",
    "    auc = roc_auc_score(y_test, probabilities, multi_class='ovr')\n",
    "    print(y_test)\n",
    "    print(y_pred)\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Calculate sensitivity (recall)\n",
    "    sensitivity = recall_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Calculate specificity\n",
    "    def specificity_score(y_true, y_pred):\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        specificity_score = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "        return specificity_score\n",
    "\n",
    "    specificity = specificity_score(y_test, y_pred)\n",
    "\n",
    "    # Calculate precision\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Calculate F1-score\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Print the metrics\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Sensitivity:\", sensitivity)\n",
    "    print(\"Specificity:\", specificity)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"F1-score:\", f1)\n",
    "    print(\"AUC:\", auc)\n",
    "    print(classification_report(y_test, y_pred, target_names=class_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 8s 1s/step - loss: 1.3665 - accuracy: 0.4128 - val_loss: 0.8564 - val_accuracy: 0.5479\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.9326 - accuracy: 0.6239 - val_loss: 0.9147 - val_accuracy: 0.5205\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.6569 - accuracy: 0.8073 - val_loss: 0.5929 - val_accuracy: 0.6986\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4831 - accuracy: 0.8440 - val_loss: 0.4766 - val_accuracy: 0.8082\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.4226 - accuracy: 0.8257 - val_loss: 0.7469 - val_accuracy: 0.7534\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.5594 - accuracy: 0.8440 - val_loss: 0.7341 - val_accuracy: 0.6849\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.4523 - accuracy: 0.8165 - val_loss: 0.7908 - val_accuracy: 0.7123\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.3760 - accuracy: 0.7982 - val_loss: 0.4319 - val_accuracy: 0.7945\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.2007 - accuracy: 0.9358 - val_loss: 0.3546 - val_accuracy: 0.8630\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.3025 - accuracy: 0.8624 - val_loss: 0.4008 - val_accuracy: 0.8493\n",
      "Time: 59.561301708221436\n"
     ]
    }
   ],
   "source": [
    "# Set the directory path where your images are located\n",
    "DIRECTORY = r\"E:\\Spring 23\\SBEN424 - Advanced Image processing\\Project\"\n",
    "# Set the target size for resizing the images\n",
    "target_size = (256, 256)  # Adjust the size as needed\n",
    "\n",
    "# Load and preprocess the images from the directory\n",
    "image_array, label_array, class_labels = load_images_from_directory(\n",
    "    DIRECTORY, target_size)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    image_array, label_array, test_size=0.4, random_state=42)\n",
    "\n",
    "# Starting time\n",
    "start = time.time()\n",
    "\n",
    "# Train the CNN model\n",
    "label_encoder = LabelEncoder()\n",
    "model = cnn_model(y_train, y_test, X_train, X_test, label_encoder, target_size)\n",
    "\n",
    "# Ending time\n",
    "end = time.time()\n",
    "\n",
    "\n",
    "print(\"Time:\", (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 236ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sultaan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\arraysetops.py:608: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask &= (ar1 != a)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\Spring 23\\SBEN424 - Advanced Image processing\\Project\\project.ipynb Cell 7\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Spring%2023/SBEN424%20-%20Advanced%20Image%20processing/Project/project.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m############## Evaluate the model ##################\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Spring%2023/SBEN424%20-%20Advanced%20Image%20processing/Project/project.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m evaluate_model(model, y_test, X_test, class_labels, label_encoder)\n",
      "\u001b[1;32me:\\Spring 23\\SBEN424 - Advanced Image processing\\Project\\project.ipynb Cell 7\u001b[0m in \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Spring%2023/SBEN424%20-%20Advanced%20Image%20processing/Project/project.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Convert probabilities to class labels\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Spring%2023/SBEN424%20-%20Advanced%20Image%20processing/Project/project.ipynb#X33sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m y_pred \u001b[39m=\u001b[39m probabilities\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Spring%2023/SBEN424%20-%20Advanced%20Image%20processing/Project/project.ipynb#X33sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m y_pred \u001b[39m=\u001b[39m label_encoder\u001b[39m.\u001b[39;49mtransform(y_pred)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Spring%2023/SBEN424%20-%20Advanced%20Image%20processing/Project/project.ipynb#X33sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Calculate AUC\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Spring%2023/SBEN424%20-%20Advanced%20Image%20processing/Project/project.ipynb#X33sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m auc \u001b[39m=\u001b[39m roc_auc_score(y_test, probabilities, multi_class\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39movr\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Sultaan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:138\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[39mif\u001b[39;00m _num_samples(y) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    136\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([])\n\u001b[1;32m--> 138\u001b[0m \u001b[39mreturn\u001b[39;00m _encode(y, uniques\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclasses_)\n",
      "File \u001b[1;32mc:\\Users\\Sultaan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_encode.py:187\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     \u001b[39mif\u001b[39;00m check_unknown:\n\u001b[1;32m--> 187\u001b[0m         diff \u001b[39m=\u001b[39m _check_unknown(values, uniques)\n\u001b[0;32m    188\u001b[0m         \u001b[39mif\u001b[39;00m diff:\n\u001b[0;32m    189\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my contains previously unseen labels: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(diff)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Sultaan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_encode.py:261\u001b[0m, in \u001b[0;36m_check_unknown\u001b[1;34m(values, known_values, return_mask)\u001b[0m\n\u001b[0;32m    258\u001b[0m         valid_mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones(\u001b[39mlen\u001b[39m(values), dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n\u001b[0;32m    260\u001b[0m \u001b[39m# check for nans in the known_values\u001b[39;00m\n\u001b[1;32m--> 261\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39;49misnan(known_values)\u001b[39m.\u001b[39many():\n\u001b[0;32m    262\u001b[0m     diff_is_nan \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39misnan(diff)\n\u001b[0;32m    263\u001b[0m     \u001b[39mif\u001b[39;00m diff_is_nan\u001b[39m.\u001b[39many():\n\u001b[0;32m    264\u001b[0m         \u001b[39m# removes nan from valid_mask\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "############## Evaluate the model ##################\n",
    "evaluate_model(model, y_test, X_test, class_labels, label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on new data\n",
    "# new_data = [...]  # Replace [...] with your new data\n",
    "# preprocessed_data = [...]  # Preprocess the new data\n",
    "# predictions = model.predict(preprocessed_data)\n",
    "\n",
    "# # Print the predicted class labels\n",
    "# predicted_labels = np.argmax(predictions, axis=1)\n",
    "# class_labels = [\"normal\", \"exudates\", \"drusen\"]\n",
    "# for label in predicted_labels:\n",
    "#     print(class_labels[label])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
