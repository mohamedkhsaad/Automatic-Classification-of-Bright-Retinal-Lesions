{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pylint: disable=no-member, missing-function-docstring\n",
    "\"\"\"Classification Algorithm that classify retinal image to three classes: \n",
    "Normal, Drusen, and Exudate retinal fundus images.\n",
    "Platform: Python 3.10.7 64-bit\n",
    "Evaluation Criteria: \n",
    "    - Sensitivity, specificity, accuracy, F-score, AUC, and confusion matrix\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, classification_report\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### preprocess the images ###########################\n",
    "def preprocess_image(image_path, target_size):\n",
    "    # Load and preprocess a single image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB format\n",
    "    # Resize the image using bilinear interpolation\n",
    "    image = cv2.resize(image, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "    # Normalize the image pixel values to 0-1 scale\n",
    "    image = image.astype('float32')/255.0\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### Load the images ###############################\n",
    "def load_images_from_directory(directory, target_size):\n",
    "    image_list = []\n",
    "    label_list = []\n",
    "\n",
    "    # Specify the class labels\n",
    "    class_labels = [\"normal\", \"exudates\", \"drusen\"]\n",
    "\n",
    "    # Iterate over the subdirectories (classes) in the directory\n",
    "    for class_name in class_labels:\n",
    "        class_dir = os.path.join(directory, class_name)\n",
    "        if os.path.isdir(class_dir):\n",
    "            # Iterate over the images in the class directory\n",
    "            for filename in os.listdir(class_dir):\n",
    "                # Adjust the file extensions as needed\n",
    "                if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                    image_path = os.path.join(class_dir, filename)\n",
    "                    image = preprocess_image(image_path, target_size)\n",
    "                    image_list.append(image)\n",
    "                    label_list.append(class_name)\n",
    "\n",
    "    # Convert the image list and label list to NumPy arrays\n",
    "    image_array = np.array(image_list)\n",
    "    label_array = np.array(label_list)\n",
    "\n",
    "    return image_array, label_array, class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# Training the CNN model #################################\n",
    "def cnn_model(y_train, y_test, X_train, X_test, label_encoder, target_size):\n",
    "\n",
    "    # Convert the string labels to numeric format\n",
    "    y_train = label_encoder.fit_transform(y_train)\n",
    "    y_test = label_encoder.transform(y_test)\n",
    "\n",
    "    # Define the CNN model architecture\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu',\n",
    "              input_shape=(target_size[0], target_size[1], 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=32,\n",
    "              validation_data=(X_test, y_test))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### Evaluate the model on the test data ###############################\n",
    "def evaluate_model(model, y_test, X_test, class_labels, label_encoder):\n",
    "    # Make predictions on the test set\n",
    "    probabilities = model.predict(X_test)\n",
    "    # Convert probabilities to class labels\n",
    "    y_pred = probabilities.argmax(axis=1)\n",
    "\n",
    "    y_pred = label_encoder.inverse_transform(y_pred)\n",
    "    # y_test = label_encoder.inverse_transform(y_test)\n",
    "\n",
    "    # Calculate AUC\n",
    "    auc = roc_auc_score(y_test, probabilities, multi_class='ovr')\n",
    "    print(y_test)\n",
    "    print(y_pred)\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Calculate sensitivity (recall)\n",
    "    sensitivity = recall_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Calculate specificity\n",
    "    def specificity_score(y_true, y_pred):\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        specificity_score = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "        return specificity_score\n",
    "\n",
    "    specificity = specificity_score(y_test, y_pred)\n",
    "\n",
    "    # Calculate precision\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Calculate F1-score\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Print the metrics\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Sensitivity:\", sensitivity)\n",
    "    print(\"Specificity:\", specificity)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"F1-score:\", f1)\n",
    "    print(\"AUC:\", auc)\n",
    "    print(classification_report(y_test, y_pred, target_names=class_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the directory path where your images are located\n",
    "DIRECTORY = r\"E:\\Spring 23\\SBEN424 - Advanced Image processing\\Project\"\n",
    "# Set the target size for resizing the images\n",
    "target_size = (256, 256)  # Adjust the size as needed\n",
    "\n",
    "# Load and preprocess the images from the directory\n",
    "image_array, label_array, class_labels = load_images_from_directory(\n",
    "    DIRECTORY, target_size)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    image_array, label_array, test_size=0.4, random_state=42)\n",
    "\n",
    "# Starting time\n",
    "start = time.time()\n",
    "\n",
    "# Train the CNN model\n",
    "label_encoder = LabelEncoder()\n",
    "model = cnn_model(y_train, y_test, X_train, X_test, label_encoder, target_size)\n",
    "\n",
    "# Ending time\n",
    "end = time.time()\n",
    "\n",
    "evaluate_model(model, y_test, X_test, class_labels, label_encoder)\n",
    "print(\"Time:\", (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on new data\n",
    "# new_data = [...]  # Replace [...] with your new data\n",
    "# preprocessed_data = [...]  # Preprocess the new data\n",
    "# predictions = model.predict(preprocessed_data)\n",
    "\n",
    "# # Print the predicted class labels\n",
    "# predicted_labels = np.argmax(predictions, axis=1)\n",
    "# class_labels = [\"normal\", \"exudates\", \"drusen\"]\n",
    "# for label in predicted_labels:\n",
    "#     print(class_labels[label])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
